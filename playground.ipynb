{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81564dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "fpath = \"/graft3/datasets/pnlong/lnac/sashimi/data/musdb18stereo/valid/\"\n",
    "# get length of each file in fpath\n",
    "import os\n",
    "\n",
    "\n",
    "lengths = {}\n",
    "for f in tqdm.tqdm(os.listdir(fpath)):\n",
    "    if f.endswith(\".wav\"):\n",
    "        info = torchaudio.info(os.path.join(fpath, f))\n",
    "        print(f, info.num_frames)\n",
    "        lengths[f] = info.num_frames\n",
    "\n",
    "# write to json\n",
    "import json\n",
    "with open(\"musdbstereo_lengths_valid.json\", \"w\") as f:\n",
    "    json.dump(lengths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for given path, get length, sampling rate, and bit depth\n",
    "import torchaudio\n",
    "import os\n",
    "import tqdm\n",
    "def get_wav_info(path):\n",
    "    # get length, sr, bit depth, and # of chanels\n",
    "    info = torchaudio.info(path)\n",
    "    return info.num_frames, info.sample_rate, info.bits_per_sample, info.num_channels\n",
    "\n",
    "pth = '/graft3/datasets/znovack/trilobyte/Pro/'\n",
    "wav_info = {}\n",
    "for root, _, files in tqdm.tqdm(os.walk(pth)):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(('.flac', '.wav')):\n",
    "            full_path = os.path.join(root, f)\n",
    "            try:\n",
    "                length, sr, bps, ch = get_wav_info(full_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {full_path}: {e}\")\n",
    "                continue\n",
    "            key = os.path.basename(full_path)\n",
    "            wav_info[key] = {'length': length, 'sample_rate': sr, 'bits_per_sample': bps, 'n_channels': ch}\n",
    "            \n",
    "import json\n",
    "with open('trilobyte_pro_info.json', 'w') as f:\n",
    "    json.dump(wav_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine amateur and freeload datasets, filtering out mono files\n",
    "# then filter out mono for pro dataset as well\n",
    "import json\n",
    "with open('trilobyte_amateur_info.json', 'r') as f:\n",
    "    amateur_info = json.load(f)\n",
    "with open('trilobyte_freeload_info.json', 'r') as f:\n",
    "    freeload_info = json.load(f)\n",
    "with open('trilobyte_pro_info.json', 'r') as f:\n",
    "    pro_info = json.load(f)\n",
    "train_info = {}\n",
    "for d in [amateur_info, freeload_info]:\n",
    "    for k, v in d.items():\n",
    "        # if v['n_channels'] > 1:\n",
    "        train_info[k] = v\n",
    "\n",
    "valid_info = {}\n",
    "for k, v in pro_info.items():\n",
    "    # if v['n_channels'] > 1:\n",
    "    valid_info[k] = v\n",
    "\n",
    "with open('trilobyte_train_stereo_info.json', 'w') as f:\n",
    "    json.dump(train_info, f)\n",
    "with open('trilobyte_valid_stereo_info.json', 'w') as f:\n",
    "    json.dump(valid_info, f)\n",
    "\n",
    "\n",
    "# make one that just lumps all trilobyte data together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0edcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('trilobyte_amateur_info.json', 'r') as f:\n",
    "    amateur_info = json.load(f)\n",
    "with open('trilobyte_freeload_info.json', 'r') as f:\n",
    "    freeload_info = json.load(f)\n",
    "with open('trilobyte_pro_info.json', 'r') as f:\n",
    "    pro_info = json.load(f)\n",
    "all_info = {}\n",
    "for d in [amateur_info, freeload_info, pro_info]:\n",
    "    for k, v in d.items():\n",
    "        # if v['n_channels'] > 1:\n",
    "        all_info[k] = v\n",
    "with open('trilobyte_all_stereo_info.json', 'w') as f:\n",
    "    json.dump(all_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make random 90-10 split of trilobyte_all_stereo_info.json\n",
    "import json\n",
    "import random\n",
    "with open('trilobyte_all_stereo_info.json', 'r') as f:\n",
    "    all_info = json.load(f)\n",
    "all_keys = list(all_info.keys())\n",
    "random.shuffle(all_keys)\n",
    "n = len(all_keys)\n",
    "train_keys = all_keys[:int(0.9 * n)]\n",
    "valid_keys = all_keys[int(0.9 * n):]\n",
    "train_info = {k: all_info[k] for k in train_keys}\n",
    "valid_info = {k: all_info[k] for k in valid_keys}\n",
    "with open('trilobyte_random_train_stereo_info.json', 'w') as f:\n",
    "    json.dump(train_info, f)\n",
    "with open('trilobyte_random_valid_stereo_info.json', 'w') as f:\n",
    "    json.dump(valid_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44039677",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ca10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load\n",
    "with open('trilobyte_pro_info.json', 'r') as f:\n",
    "    wav_info = json.load(f)\n",
    "\n",
    "# get statistics\n",
    "lengths = [v['length'] for v in wav_info.values()]\n",
    "sample_rates = [v['sample_rate'] for v in wav_info.values()]\n",
    "bit_depths = [v['bits_per_sample'] for v in wav_info.values()]\n",
    "channels = [v['n_channels'] for v in wav_info.values()]\n",
    "import numpy as np\n",
    "print(\"Length: min {}, max {}, mean {}, std {}\".format(np.min(lengths), np.max(lengths), np.mean(lengths), np.std(lengths)))\n",
    "print(\"Sample Rate: min {}, max {}, mean {}, std {}\".format(np.min(sample_rates), np.max(sample_rates), np.mean(sample_rates), np.std(sample_rates)))\n",
    "print(\"Bit Depth: min {}, max {}, mean {}, std {}\".format(np.min(bit_depths), np.max(bit_depths), np.mean(bit_depths), np.std(bit_depths)))\n",
    "print(\"Channels: min {}, max {}, mean {}, std {}\".format(np.min(channels), np.max(channels), np.mean(channels), np.std(channels)))\n",
    "\n",
    "# get count of unique sample rates, bit depths, and channels\n",
    "from collections import Counter\n",
    "sr_counts = Counter(sample_rates)\n",
    "bps_counts = Counter(bit_depths)\n",
    "ch_counts = Counter(channels)\n",
    "print(\"Sample Rate Counts:\", sr_counts)\n",
    "print(\"Bit Depth Counts:\", bps_counts)\n",
    "print(\"Channel Counts:\", ch_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec173f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wav_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da71d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
